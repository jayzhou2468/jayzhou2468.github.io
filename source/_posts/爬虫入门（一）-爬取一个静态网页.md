---
title: 爬虫入门（一） 爬取一个静态网页
catalog: true
date: 2018-11-28 11:22:46
subtitle: 开始爬爬爬的学习
header-img: "/img/article_header/pachong1.png"
tags:
- 爬虫
catagories:
- 爬虫


---

# 爬取豆瓣TOP250电影数据
> 本文章目的是获取豆瓣电影TOP250电影名称、导演、演员、评分、上映时间、时长、别名等，网页地址为：http://movie.douban.com/top250。 使用request、beautifulsoup4库。

## 几个要点
1. 提取请求头重要的信息：header、host等，在浏览器右键审查元素-网络-获取header、host内容，如图所示。
   ![header](/img/article/header.png)

2. 下面一行代码返回一个名为r的response响应对象，其存储了服务器的响应内容。
   ```yml
   r = request.get('https://movie.douban.com/top250')
   ```
   
3. 用find、find_all寻找相应的标签

4. 最后写入txt文件。也可写入excel等其他文件中。

## 附上代码
```yml

import requests
from bs4 import BeautifulSoup

def get_movies():
print('正在从豆瓣电影Top250抓取数据......')
headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:63.0)\
Gecko/20100101 Firefox/63.0',
'Host': 'movie.douban.com'}
movie_list = []
count = 0
for i in range(0, 10):
print('正在爬取第{0}页......'.format(i+1))
link = 'http://movie.douban.com/top250?start = ' + str(i * 25)
r = requests.get(link, headers = headers,timeout = 10)
#print(str(i+1), '页响应状态码：', r.status_code)

soup = BeautifulSoup(r.text, 'lxml')
div_list = soup.find_all('div',class_='info')
for each in div_list:
count += 1
# movie = each.a.span.text.strip()
# img_url = each.previous_sibling.previous_sibling.a.img['src']
movie = each.find('div', class_='hd').get_text(strip=True).replace('\xa0', '').replace('[可播放]', '')
actor = list(each.find('p', class_='').strings)[0].strip().replace('\xa0', '')
# 将生成器list化后索引，strip()去除两边空格再用空字符替换&nbsp
type = list(each.find('p', class_='').strings)[1].strip().replace('\xa0', '')
score = each.find('div', class_='star').get_text('/', strip=True)

if each.find('span', class_='inq'):     # 注意有部电影没有总结，也就没有<span class="inq">标签这里用if检测一下防止None使用string方法报错
quote = each.find('span', class_='inq').string
else:
quote = '这部电影没有总结'
#movie_list.extend([img_url,movie,actor,type,score,quote])
obj = str(count) + ' ' + movie + ' ' + actor + ' ' + type + ' ' + score + ' ' + quote + '\n'
print(obj,end='')
#print(count,img_url,movie,actor,type,score,quote)
with open('douban.txt', 'a+') as f:     # a+、r+、w+区别
f.write(obj)
f.close()
return movie_list

print(get_movies())

```

## 爬取结果

![result1](/img/article/result1.png)
![result2](/img/article/result2.png)

代码亲测可用，如果没有安装request、bs4库先import两个库。



















